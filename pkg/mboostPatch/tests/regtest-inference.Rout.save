
R version 3.2.1 (2015-06-18) -- "World-Famous Astronaut"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> require("mboost")
Loading required package: mboost
Loading required package: parallel
Loading required package: stabs
This is mboost 2.5-0. See 'package?mboost' and 'news(package  = "mboost")'
for a complete list of changes.

> 
> set.seed(1907)
> 
> ### check confidence intervals
> data("bodyfat", package = "TH.data")
> bodyfat$ID <- factor(sample(1:5, size = nrow(bodyfat), replace = TRUE))
> glm <- glmboost(DEXfat ~ ., data = bodyfat)
> gam <- gamboost(DEXfat ~ ., data = bodyfat)
Warning message:
In bbs(as.data.frame(list(...)), df = dfbase) :
  cannot compute 'bbs' for non-numeric variables; used 'bols' instead.
> 
> refit <- glm$update(weights = model.weights(glm), risk = "inbag")
> stopifnot(all.equal(coef(refit), coef(glm)))
> 
> glm[200]

	 Generalized Linear Models Fitted via Gradient Boosting

Call:
glmboost.formula(formula = DEXfat ~ ., data = bodyfat)


	 Squared Error (Regression) 

Loss function: (y - f)^2 
 

Number of boosting iterations: mstop = 200 
Step size:  0.1 
Offset:  30.78282 

Coefficients: 
  (Intercept)           age     waistcirc       hipcirc  elbowbreadth 
-98.267586175   0.007743431   0.189304614   0.365744326  -0.118303213 
  kneebreadth      anthro3a      anthro3b      anthro3c           ID2 
  1.613621424   3.326860270   3.458883502   0.514108117  -0.833010169 
          ID3           ID4           ID5 
 -0.925934420  -1.979498322  -1.771987847 
attr(,"offset")
[1] 30.78282

> confint.glm <- confint(glm, B = 100, B.mstop = 2)
There were 50 or more warnings (use warnings() to see the first 50)
> confint.glm
	Bootstrap Confidence Intervals
                     2.5%        97.5%
(Intercept)  -78.05959532 -48.53585992
age           -0.01006118   0.04787764
waistcirc      0.08009208   0.29340444
hipcirc        0.20586965   0.52028270
elbowbreadth  -1.28224120   1.00828926
kneebreadth    0.03202871   3.13241905
anthro3a       0.00000000   7.16424617
anthro3b       0.00000000   6.34765206
anthro3c       0.00000000   4.03626864
anthro4        0.00000000   3.96809690
ID2           -1.91672133   1.16889159
ID3           -2.03416976   0.37211182
ID4           -3.33076662   0.00000000
ID5           -3.22332317   0.33953241
> 
> confint.gam <- confint(gam, B = 100, B.mstop = 1)
Start computing bootstrap confidence intervals... 
B = 1B = 2B = 3B = 4B = 5B = 6B = 7B = 8B = 9B = 10B = 11B = 12B = 13B = 14B = 15B = 16B = 17B = 18B = 19B = 20B = 21B = 22B = 23B = 24B = 25B = 26B = 27B = 28B = 29B = 30B = 31B = 32B = 33B = 34B = 35B = 36B = 37B = 38B = 39B = 40B = 41B = 42B = 43B = 44B = 45B = 46B = 47B = 48B = 49B = 50B = 51B = 52B = 53B = 54B = 55B = 56B = 57B = 58B = 59B = 60B = 61B = 62B = 63B = 64B = 65B = 66B = 67B = 68B = 69B = 70B = 71B = 72B = 73B = 74B = 75B = 76B = 77B = 78B = 79B = 80B = 81B = 82B = 83B = 84B = 85B = 86B = 87B = 88B = 89B = 90B = 91B = 92B = 93B = 94B = 95B = 96B = 97B = 98B = 99B = 100
There were 50 or more warnings (use warnings() to see the first 50)
> plot(confint.gam, which = 1)
> plot(confint.gam, which = 2)
> plot(confint.gam, which = 3)
> 
> 
> ### check cvrisk (it should run even if a fold leads to an error)
> folds <- cv(model.weights(glm), type = "kfold")
> folds[1, 1] <- NA
> 
> cvrisk(glm, folds = folds, papply = lapply)
Error in if (max(abs(w - floor(w))) < sqrt(.Machine$double.eps)) return(w) : 
  missing value where TRUE/FALSE needed

	 Cross-validated Squared Error (Regression) 
	 glmboost.formula(formula = DEXfat ~ ., data = bodyfat) 

        1         2         3         4         5         6         7         8 
106.05983  89.47032  76.79013  66.58719  57.40810  50.82164  46.64790  41.05777 
        9        10        11        12        13        14        15        16 
 36.48812  33.19998  30.50682  28.01627  25.62120  23.71550  21.62943  20.79692 
       17        18        19        20        21        22        23        24 
 20.44041  19.50499  18.51749  17.88003  17.29163  16.50449  16.04358  15.46808 
       25        26        27        28        29        30        31        32 
 14.85138  14.79477  14.91969  14.78537  14.51518  14.48172  14.37897  14.14888 
       33        34        35        36        37        38        39        40 
 14.00657  13.78886  13.55755  13.66054  14.12455  14.08090  14.07382  14.19040 
       41        42        43        44        45        46        47        48 
 14.13243  13.99379  13.81825  13.60565  13.36881  13.53934  13.90801  13.86412 
       49        50        51        52        53        54        55        56 
 13.84749  13.87333  13.87685  13.77815  13.59780  13.30215  13.19600  13.36171 
       57        58        59        60        61        62        63        64 
 13.69221  13.68240  13.69068  13.75575  13.68125  13.62657  13.51172  13.23080 
       65        66        67        68        69        70        71        72 
 13.08462  13.26783  13.62461  13.61572  13.55941  13.67998  13.68824  13.60537 
       73        74        75        76        77        78        79        80 
 13.39517  13.13689  13.07962  13.27727  13.55709  13.50742  13.55059  13.69696 
       81        82        83        84        85        86        87        88 
 13.66784  13.58510  13.35726  13.15318  13.06756  13.28021  13.60265  13.54893 
       89        90        91        92        93        94        95        96 
 13.55018  13.68764  13.65251  13.60917  13.39456  13.15441  13.09118  13.30370 
       97        98        99       100       101       102       103       104 
 13.61654  13.57046  13.54405  13.68758  13.64161  13.59458  13.36824  13.16229 
      105       106       107       108       109       110       111       112 
 13.07483  13.27718  13.53249  13.49819  13.54978  13.65819  13.63435  13.55037 
      113       114       115       116       117       118       119       120 
 13.36185  13.15877  13.08040  13.27590  13.57375  13.53605  13.56789  13.69498 
      121       122       123       124       125       126       127       128 
 13.64835  13.57408  13.35846  13.13556  13.09753  13.28606  13.55568  13.51158 
      129       130       131       132       133       134       135       136 
 13.56492  13.67853  13.63492  13.56008  13.37485  13.13712  13.08867  13.28115 
      137       138       139       140       141       142       143       144 
 13.54595  13.49658  13.53460  13.65929  13.62886  13.55233  13.35296  13.12425 
      145       146       147       148       149       150       151       152 
 13.06587  13.26551  13.57304  13.51934  13.52983  13.64250  13.62194  13.55012 
      153       154       155       156       157       158       159       160 
 13.34593  13.11568  13.04806  13.25021  13.52598  13.50933  13.53118  13.64226 
      161       162       163       164       165       166       167       168 
 13.60388  13.54616  13.34827  13.12850  13.06027  13.25435  13.54897  13.50814 
      169       170       171       172       173       174       175       176 
 13.51569  13.63704  13.63127  13.56945  13.35057  13.11050  13.05242  13.27494 
      177       178       179       180       181       182       183       184 
 13.55913  13.49480  13.50666  13.64487  13.64334  13.55679  13.32917  13.11151 
      185       186       187       188       189       190       191       192 
 13.07285  13.26650  13.54186  13.48679  13.52635  13.63338  13.63288  13.55830 
      193       194       195       196       197       198       199       200 
 13.33694  13.12196  13.06018  13.27669  13.54266  13.49291  13.51663  13.64130 

	 Optimal number of boosting iterations: 155 
Warning message:
In cvrisk.mboost(glm, folds = folds, papply = lapply) :
  1 fold(s) encountered an error. Results are based on 9 folds only.
Original error message(s):
Error in if (max(abs(w - floor(w))) < sqrt(.Machine$double.eps)) return(w) : 
  missing value where TRUE/FALSE needed

> cvrisk(glm, folds = folds, papply = mclapply)

	 Cross-validated Squared Error (Regression) 
	 glmboost.formula(formula = DEXfat ~ ., data = bodyfat) 

        1         2         3         4         5         6         7         8 
106.05983  89.47032  76.79013  66.58719  57.40810  50.82164  46.64790  41.05777 
        9        10        11        12        13        14        15        16 
 36.48812  33.19998  30.50682  28.01627  25.62120  23.71550  21.62943  20.79692 
       17        18        19        20        21        22        23        24 
 20.44041  19.50499  18.51749  17.88003  17.29163  16.50449  16.04358  15.46808 
       25        26        27        28        29        30        31        32 
 14.85138  14.79477  14.91969  14.78537  14.51518  14.48172  14.37897  14.14888 
       33        34        35        36        37        38        39        40 
 14.00657  13.78886  13.55755  13.66054  14.12455  14.08090  14.07382  14.19040 
       41        42        43        44        45        46        47        48 
 14.13243  13.99379  13.81825  13.60565  13.36881  13.53934  13.90801  13.86412 
       49        50        51        52        53        54        55        56 
 13.84749  13.87333  13.87685  13.77815  13.59780  13.30215  13.19600  13.36171 
       57        58        59        60        61        62        63        64 
 13.69221  13.68240  13.69068  13.75575  13.68125  13.62657  13.51172  13.23080 
       65        66        67        68        69        70        71        72 
 13.08462  13.26783  13.62461  13.61572  13.55941  13.67998  13.68824  13.60537 
       73        74        75        76        77        78        79        80 
 13.39517  13.13689  13.07962  13.27727  13.55709  13.50742  13.55059  13.69696 
       81        82        83        84        85        86        87        88 
 13.66784  13.58510  13.35726  13.15318  13.06756  13.28021  13.60265  13.54893 
       89        90        91        92        93        94        95        96 
 13.55018  13.68764  13.65251  13.60917  13.39456  13.15441  13.09118  13.30370 
       97        98        99       100       101       102       103       104 
 13.61654  13.57046  13.54405  13.68758  13.64161  13.59458  13.36824  13.16229 
      105       106       107       108       109       110       111       112 
 13.07483  13.27718  13.53249  13.49819  13.54978  13.65819  13.63435  13.55037 
      113       114       115       116       117       118       119       120 
 13.36185  13.15877  13.08040  13.27590  13.57375  13.53605  13.56789  13.69498 
      121       122       123       124       125       126       127       128 
 13.64835  13.57408  13.35846  13.13556  13.09753  13.28606  13.55568  13.51158 
      129       130       131       132       133       134       135       136 
 13.56492  13.67853  13.63492  13.56008  13.37485  13.13712  13.08867  13.28115 
      137       138       139       140       141       142       143       144 
 13.54595  13.49658  13.53460  13.65929  13.62886  13.55233  13.35296  13.12425 
      145       146       147       148       149       150       151       152 
 13.06587  13.26551  13.57304  13.51934  13.52983  13.64250  13.62194  13.55012 
      153       154       155       156       157       158       159       160 
 13.34593  13.11568  13.04806  13.25021  13.52598  13.50933  13.53118  13.64226 
      161       162       163       164       165       166       167       168 
 13.60388  13.54616  13.34827  13.12850  13.06027  13.25435  13.54897  13.50814 
      169       170       171       172       173       174       175       176 
 13.51569  13.63704  13.63127  13.56945  13.35057  13.11050  13.05242  13.27494 
      177       178       179       180       181       182       183       184 
 13.55913  13.49480  13.50666  13.64487  13.64334  13.55679  13.32917  13.11151 
      185       186       187       188       189       190       191       192 
 13.07285  13.26650  13.54186  13.48679  13.52635  13.63338  13.63288  13.55830 
      193       194       195       196       197       198       199       200 
 13.33694  13.12196  13.06018  13.27669  13.54266  13.49291  13.51663  13.64130 

	 Optimal number of boosting iterations: 155 
Warning messages:
1: In papply(1:ncol(folds), function(i) dummyfct(weights = folds[,  :
  1 function calls resulted in an error
2: In cvrisk.mboost(glm, folds = folds, papply = mclapply) :
  1 fold(s) encountered an error. Results are based on 9 folds only.
Original error message(s):
Error in if (max(abs(w - floor(w))) < sqrt(.Machine$double.eps)) return(w) : 
  missing value where TRUE/FALSE needed

> 
> proc.time()
   user  system elapsed 
 37.871  10.398  42.425 
