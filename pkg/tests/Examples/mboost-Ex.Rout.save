
R version 2.9.0 (2009-04-17)
Copyright (C) 2009 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ### * <HEADER>
> ###
> attach(NULL, name = "CheckExEnv")
> assign("nameEx",
+        local({
+ 	   s <- "__{must remake R-ex/*.R}__"
+            function(new) {
+                if(!missing(new)) s <<- new else s
+            }
+        }),
+        pos = "CheckExEnv")
> ## Add some hooks to label plot pages for base and grid graphics
> assign("base_plot_hook",
+        function() {
+            pp <- par(c("mfg","mfcol","oma","mar"))
+            if(all(pp$mfg[1:2] == c(1, pp$mfcol[2]))) {
+                outer <- (oma4 <- pp$oma[4]) > 0; mar4 <- pp$mar[4]
+                mtext(sprintf("help(\"%s\")", nameEx()), side = 4,
+                      line = if(outer)max(1, oma4 - 1) else min(1, mar4 - 1),
+                outer = outer, adj = 1, cex = .8, col = "orchid", las=3)
+            }
+        },
+        pos = "CheckExEnv")
> assign("grid_plot_hook",
+        function() {
+            grid::pushViewport(grid::viewport(width=grid::unit(1, "npc") -
+                               grid::unit(1, "lines"), x=0, just="left"))
+            grid::grid.text(sprintf("help(\"%s\")", nameEx()),
+                            x=grid::unit(1, "npc") + grid::unit(0.5, "lines"),
+                            y=grid::unit(0.8, "npc"), rot=90,
+                            gp=grid::gpar(col="orchid"))
+        },
+        pos = "CheckExEnv")
> setHook("plot.new",     get("base_plot_hook", pos = "CheckExEnv"))
> setHook("persp",        get("base_plot_hook", pos = "CheckExEnv"))
> setHook("grid.newpage", get("grid_plot_hook", pos = "CheckExEnv"))
> assign("cleanEx",
+        function(env = .GlobalEnv) {
+ 	   rm(list = ls(envir = env, all.names = TRUE), envir = env)
+            RNGkind("default", "default")
+ 	   set.seed(1)
+    	   options(warn = 1)
+ 	   .CheckExEnv <- as.environment("CheckExEnv")
+ 	   delayedAssign("T", stop("T used instead of TRUE"),
+ 		  assign.env = .CheckExEnv)
+ 	   delayedAssign("F", stop("F used instead of FALSE"),
+ 		  assign.env = .CheckExEnv)
+ 	   sch <- search()
+ 	   newitems <- sch[! sch %in% .oldSearch]
+ 	   for(item in rev(newitems))
+                eval(substitute(detach(item), list(item=item)))
+ 	   missitems <- .oldSearch[! .oldSearch %in% sch]
+ 	   if(length(missitems))
+ 	       warning("items ", paste(missitems, collapse=", "),
+ 		       " have been removed from the search path")
+        },
+        pos = "CheckExEnv")
> assign("ptime", proc.time(), pos = "CheckExEnv")
> ## at least one package changes these via ps.options(), so do this
> ## before loading the package.
> ## Use postscript as incomplete files may be viewable, unlike PDF.
> ## Choose a size that is close to on-screen devices, fix paper
> ps.options(width = 7, height = 7, paper = "a4", reset = TRUE)
> grDevices::postscript("mboost-Ex.ps")
> 
> assign("par.postscript", graphics::par(no.readonly = TRUE), pos = "CheckExEnv")
> options(contrasts = c(unordered = "contr.treatment", ordered = "contr.poly"))
> options(warn = 1)
> library('mboost')
Loading required package: Matrix
Loading required package: lattice

Attaching package: 'Matrix'


	The following object(s) are masked from package:stats :

	 contr.helmert,
	 contr.poly,
	 contr.SAS,
	 contr.sum,
	 contr.treatment,
	 xtabs 


	The following object(s) are masked from package:base :

	 rcond 

Loading required package: splines
Loading required package: survival
Warning in namespaceImportFrom(self, asNamespace(ns)) :
  replacing previous import: contr.helmert
Warning in namespaceImportFrom(self, asNamespace(ns)) :
  replacing previous import: contr.poly
Warning in namespaceImportFrom(self, asNamespace(ns)) :
  replacing previous import: contr.SAS
Warning in namespaceImportFrom(self, asNamespace(ns)) :
  replacing previous import: contr.sum
Warning in namespaceImportFrom(self, asNamespace(ns)) :
  replacing previous import: contr.treatment
Warning in namespaceImportFrom(self, asNamespace(ns)) :
  replacing previous import: cov2cor
Warning in namespaceImportFrom(self, asNamespace(ns)) :
  replacing previous import: update
Warning in namespaceImportFrom(self, asNamespace(ns)) :
  replacing previous import: xtabs
> 
> assign(".oldSearch", search(), pos = 'CheckExEnv')
> assign(".oldNS", loadedNamespaces(), pos = 'CheckExEnv')
> cleanEx(); nameEx("FP")
> ### * FP
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: FP
> ### Title: Fractional Polynomials
> ### Aliases: FP
> ### Keywords: datagen
> 
> ### ** Examples
> 
> 
>     data("bodyfat", package = "mboost")
>     tbodyfat <- bodyfat
> 
>     ### map covariates into [1, 2]
>     indep <- names(tbodyfat)[-2]
>     tbodyfat[indep] <- lapply(bodyfat[indep], function(x) {
+         x <- x - min(x)
+         x / max(x) + 1
+     })
> 
>     ### generate formula
>     fpfm <- as.formula(paste("DEXfat ~ ", paste("FP(", indep, ", scaling = FALSE)",
+                              collapse = "+")))
>     fpfm
DEXfat ~ FP(age, scaling = FALSE) + FP(waistcirc, scaling = FALSE) + 
    FP(hipcirc, scaling = FALSE) + FP(elbowbreadth, scaling = FALSE) + 
    FP(kneebreadth, scaling = FALSE) + FP(anthro3a, scaling = FALSE) + 
    FP(anthro3b, scaling = FALSE) + FP(anthro3c, scaling = FALSE) + 
    FP(anthro4, scaling = FALSE)
> 
>     ### fit linear model
>     bf_fp <- glmboost(fpfm, data = tbodyfat,
+                       control = boost_control(mstop = 3000))
> 
>     ### when to stop
>     mstop(aic <- AIC(bf_fp))
[1] 2480
>     plot(aic)
> 
>     ### coefficients
>     cf <- coef(bf_fp[mstop(aic)])
>     length(cf)
[1] 145
>     cf[abs(cf) > 0]
                                FP(age, scaling = FALSE)age^-2 
                                                   -1.97698853 
                         FP(age, scaling = FALSE)log(age)age^3 
                                                   -0.01230829 
                    FP(waistcirc, scaling = FALSE)waistcirc^-2 
                                                   -7.86296964 
      FP(waistcirc, scaling = FALSE)log(waistcirc)waistcirc^-2 
                                                   -7.47556696 
       FP(waistcirc, scaling = FALSE)log(waistcirc)waistcirc^3 
                                                    0.67466523 
                FP(waistcirc, scaling = FALSE)log(waistcirc)^2 
                                                    5.40114493 
                        FP(hipcirc, scaling = FALSE)hipcirc^-2 
                                                   -4.00222773 
            FP(hipcirc, scaling = FALSE)log(hipcirc)hipcirc^-2 
                                                    6.09380842 
            FP(hipcirc, scaling = FALSE)log(hipcirc)hipcirc^-1 
                                                    6.07680354 
             FP(hipcirc, scaling = FALSE)log(hipcirc)hipcirc^3 
                                                   -0.45247988 
                    FP(hipcirc, scaling = FALSE)log(hipcirc)^2 
                                                   18.07362051 
              FP(elbowbreadth, scaling = FALSE)elbowbreadth^-2 
                                                    1.19027807 
FP(kneebreadth, scaling = FALSE)log(kneebreadth)kneebreadth^-2 
                                                   -1.42177852 
FP(kneebreadth, scaling = FALSE)log(kneebreadth)kneebreadth^-1 
                                                   -3.22763358 
 FP(kneebreadth, scaling = FALSE)log(kneebreadth)kneebreadth^3 
                                                    1.85814405 
                      FP(anthro3a, scaling = FALSE)anthro3a^-2 
                                                    0.16767775 
         FP(anthro3a, scaling = FALSE)log(anthro3a)anthro3a^-2 
                                                   -8.14937266 
          FP(anthro3a, scaling = FALSE)log(anthro3a)anthro3a^3 
                                                    0.90354249 
                      FP(anthro3b, scaling = FALSE)anthro3b^-2 
                                                   -0.13985229 
          FP(anthro3b, scaling = FALSE)log(anthro3b)anthro3b^3 
                                                    1.31511811 
                      FP(anthro3c, scaling = FALSE)anthro3c^-2 
                                                  -10.94522292 
> 
> 
> 
> 
> cleanEx(); nameEx("Family")
> ### * Family
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Family
> ### Title: Gradient Boosting Families
> ### Aliases: Family AdaExp Binomial GaussClass GaussReg Huber Laplace
> ###   Poisson CoxPH QuantReg
> ### Keywords: models
> 
> ### ** Examples
> 
> 
>     Laplace()

	 Absolute Error 

Loss function: abs(y - f) 
 
> 
>     Family(ngradient = function(y, f) y - f,
+            loss = function(y, f) (y - f)^2,
+            name = "My Gauss Variant")

	 My Gauss Variant 

Loss function: (y - f)^2 
 
> 
> 
> 
> 
> cleanEx(); nameEx("Westbc")
> ### * Westbc
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Westbc
> ### Title: Breast Cancer Gene Expression
> ### Aliases: Westbc
> ### Keywords: datasets
> 
> ### ** Examples
> 
> 
>     ## Not run: 
> ##D         library("Biobase")
> ##D         data("Westbc", package = "mboost")
> ##D         westbc <- new("ExpressionSet", 
> ##D               phenoData = new("AnnotatedDataFrame", data = Westbc$pheno),
> ##D               assayData = assayDataNew(exprs = Westbc$assay))
> ##D     
> ## End(Not run)
> 
> 
> 
> cleanEx(); nameEx("baselearners")
> ### * baselearners
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: baselearners
> ### Title: Base-learners for Gradient Boosting
> ### Aliases: bols bbs bspatial brandom btree
> ### Keywords: models
> 
> ### ** Examples
> 
> 
>   x1 <- rnorm(100)
>   x2 <- rnorm(100) + 0.25*x1
>   x3 <- as.factor(sample(0:1, 100, replace = TRUE))
>   x4 <- gl(4, 25)
>   y <- 3*sin(x1) + x2^2 + rnorm(100)
> 
>   knots.x2 <- quantile(x2, c(0.25,0.5,0.75))
> 
>   spline1 <- bbs(x1, knots = 20, df = 4)
> attributes(spline1)
$names
[1] "model.frame" "get_call"    "get_data"    "get_index"   "get_vary"   
[6] "get_names"   "set_names"   "dpp"        

$class
[1] "blg"

> spline2 <- bbs(x2,knots=knots.x2,df=5)
> attributes(spline2)
$names
[1] "model.frame" "get_call"    "get_data"    "get_index"   "get_vary"   
[6] "get_names"   "set_names"   "dpp"        

$class
[1] "blg"

> olsfit <- bols(x3)
> attributes(olsfit)
$names
[1] "model.frame" "get_call"    "get_data"    "get_index"   "get_names"  
[6] "get_vary"    "set_names"   "dpp"        

$class
[1] "blg"

> 
> form1 <- y ~ bbs(x1,knots=20,df=4) + bbs(x2,knots=knots.x2,df=5)
> 
> # example for factors
> attributes(bols(x4))
$names
[1] "model.frame" "get_call"    "get_data"    "get_index"   "get_names"  
[6] "get_vary"    "set_names"   "dpp"        

$class
[1] "blg"

> 
> # example for bspatial
> 
> x1 <- runif(250,-pi,pi)
> x2 <- runif(250,-pi,pi)
> 
> y <- sin(x1)*sin(x2) + rnorm(250, sd = 0.4)
> 
> spline3 <- bspatial(x1, x2, knots=12)
Note: Method with signature "dsparseMatrix#dsparseMatrix" chosen for function "kronecker",
 target signature "dgCMatrix#dgTMatrix".
 "sparseMatrix#TsparseMatrix" would also be valid
Note: Method with signature "dsparseMatrix#dsparseMatrix" chosen for function "kronecker",
 target signature "dgTMatrix#dgCMatrix".
 "TsparseMatrix#sparseMatrix" would also be valid
Note: Method with signature "ANY#diagonalMatrix" chosen for function "kronecker",
 target signature "dsCMatrix#ddiMatrix".
 "sparseMatrix#ANY" would also be valid
Note: Method with signature "dsparseMatrix#dsparseMatrix" chosen for function "kronecker",
 target signature "dsCMatrix#dtTMatrix".
 "sparseMatrix#TsparseMatrix" would also be valid
Note: Method with signature "diagonalMatrix#ANY" chosen for function "kronecker",
 target signature "ddiMatrix#dsCMatrix".
 "ANY#sparseMatrix" would also be valid
Note: Method with signature "dsparseMatrix#dsparseMatrix" chosen for function "kronecker",
 target signature "dtTMatrix#dsCMatrix".
 "TsparseMatrix#sparseMatrix" would also be valid
> attributes(spline3)
$names
[1] "model.frame" "get_call"    "get_data"    "get_index"   "get_vary"   
[6] "get_names"   "set_names"   "dpp"        

$class
[1] "blg"

> 
> form2 <- y ~ bspatial(x1, x2, knots=12)
> 
> # decompose spatial effect into parametric part and deviation with 1 df
> 
> form2 <- y ~ bols(x1) + bols(x2) + bols(x1*x2) +
+              bspatial(x1, x2, knots=12, center = TRUE, df=1)
> 
> # random intercept
> 
> id <- factor(rep(1:10, each=5))
> raneff <- brandom(id)
> attributes(raneff)
$names
[1] "model.frame" "get_call"    "get_data"    "get_index"   "get_names"  
[6] "get_vary"    "set_names"   "dpp"        

$class
[1] "blg"

> 
> # random slope
> 
> z <- runif(50)
> raneff <- brandom(id, z=z)
> attributes(raneff)
$names
[1] "model.frame" "get_call"    "get_data"    "get_index"   "get_names"  
[6] "get_vary"    "set_names"   "dpp"        

$class
[1] "blg"

> 
> # remove intercept from base learner
> # and add explicit intercept to the model
> 
> tmpdata <- data.frame(x = 1:100, y = rnorm(1:100), int = rep(1, 100))
> mod <- gamboost(y ~ bols(int, intercept = FALSE) + bols(x, intercept = FALSE),
+                 data = tmpdata, control = boost_control(mstop = 2500))
> cf <- unlist(coef(mod))
> cf[1] <- cf[1] + mod$offset
> cf
bols(int,intercept=FALSE)   bols(x,intercept=FALSE) 
              0.239120107              -0.004211271 
> coef(lm(y ~ x, data = tmpdata))
 (Intercept)            x 
 0.239120133 -0.004211272 
> 
> 
> 
> 
> cleanEx(); nameEx("blackboost")
> ### * blackboost
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: blackboost
> ### Title: Gradient Boosting with Regression Trees
> ### Aliases: blackboost
> ### Keywords: models regression
> 
> ### ** Examples
> 
> 
>     ### a simple two-dimensional example: cars data
>     cars.gb <- blackboost(dist ~ speed, data = cars,
+                           control = boost_control(mstop = 50))
Loading required package: party
Loading required package: grid
Loading required package: modeltools
Loading required package: stats4
Loading required package: coin
Loading required package: mvtnorm
Loading required package: zoo

Attaching package: 'zoo'


	The following object(s) are masked from package:base :

	 as.Date.numeric 

Loading required package: sandwich
Loading required package: strucchange
Loading required package: vcd
Loading required package: MASS
Loading required package: colorspace
>     cars.gb

	 Model-based Boosting

Call:
blackboost(formula = dist ~ speed, data = cars, control = boost_control(mstop = 50))


	 Squared Error (Regression) 

Loss function: (y - f)^2 
 

Number of boosting iterations: mstop = 50 
Step size:  0.1 
Offset:  42.98 

Baselearner(s): 
NULL

> 
>     ### plot fit
>     plot(dist ~ speed, data = cars)
>     lines(cars$speed, predict(cars.gb), col = "red")
> 
> 
> 
> 
> cleanEx(); nameEx("bodyfat")
> ### * bodyfat
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: bodyfat
> ### Title: Prediction of Body Fat by Skinfold Thickness, Circumferences,
> ###   and Bone Breadths
> ### Aliases: bodyfat
> ### Keywords: datasets
> 
> ### ** Examples
> 
> 
>     data("bodyfat", package = "mboost")
> 
>     ### final model proposed by Garcia et al. (2005)
>     fmod <- lm(DEXfat ~ hipcirc + anthro3a + kneebreadth, data = bodyfat)
>     coef(fmod)  
(Intercept)     hipcirc    anthro3a kneebreadth 
-75.2347840   0.5115264   8.9096375   1.9019904 
> 
>     ### plot additive model for same variables
>     amod <- gamboost(DEXfat ~ hipcirc + anthro3a + kneebreadth, 
+                      data = bodyfat, baselearner = "bbs")
>     layout(matrix(1:3, ncol = 3))
>     plot(amod[mstop(AIC(amod, "corrected"))], ask = FALSE)
> 
> 
> 
> 
> cleanEx(); nameEx("boost_family-class")
> ### * boost_family-class
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: boost_family-class
> ### Title: Class "boost_family": Gradient Boosting Family
> ### Aliases: boost_family-class show,boost_family-method
> ### Keywords: classes
> 
> ### ** Examples
> 
> 
>     Laplace()

	 Absolute Error 

Loss function: abs(y - f) 
 
> 
> 
> 
> 
> cleanEx(); nameEx("cvrisk")
> ### * cvrisk
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: cvrisk
> ### Title: Cross-Validation
> ### Aliases: cvrisk cv
> ### Keywords: models regression
> 
> ### ** Examples
> 
> 
>   data("bodyfat", package = "mboost")
> 
>   ### fit linear model to data
>   model <- glmboost(DEXfat ~ ., data = bodyfat,
+                     control = boost_control(center = TRUE))
Warning in glmboost.formula(DEXfat ~ ., data = bodyfat, control = boost_control(center = TRUE)) :
  boost_control(center = TRUE) is deprecated, use glmboost(..., center = TRUE)
> 
>   ### AIC-based selection of number of boosting iterations
>   maic <- AIC(model)
>   maic
[1] 3.352738
Optimal number of boosting iterations: 45 
Degrees of freedom (for mstop = 45): 1.917234 
> 
>   ### inspect coefficient path and AIC-based stopping criterion
>   par(mai = par("mai") * c(1, 1, 1, 1.8))
>   plot(model)
>   abline(v = mstop(maic), col = "lightgray")
> 
>   ### 10-fold cross-validation
>   n <- nrow(bodyfat)
>   k <- 10
>   ntest <- floor(n / k)
>   cv10f <- cv(model.weights(model), type = "kfold")
>   cvm <- cvrisk(model, folds = cv10f)
Loading required package: multicore

Attaching package: 'multicore'


	The following object(s) are masked from package:lattice :

	 parallel 

>   print(cvm)

	 Cross-validated Squared Error (Regression) 
	 glmboost.formula(formula = DEXfat ~ ., data = bodyfat, control = boost_control(center = TRUE)) 

        1         2         3         4         5         6         7         8 
114.40523  98.06521  85.32971  73.92584  66.42888  58.58223  52.92717  48.11107 
        9        10        11        12        13        14        15        16 
 43.44177  38.82368  34.69010  32.43575  30.26747  27.69441  25.90334  24.56641 
       17        18        19        20        21        22        23        24 
 22.97080  21.83605  20.65550  19.71075  18.83332  18.12002  17.59685  16.87540 
       25        26        27        28        29        30        31        32 
 16.48051  16.18608  15.59530  15.32054  14.87441  14.63678  14.38958  14.12979 
       33        34        35        36        37        38        39        40 
 13.88300  13.68727  13.49912  13.31103  13.15311  13.03541  12.94123  12.81819 
       41        42        43        44        45        46        47        48 
 12.70313  12.66793  12.60082  12.51772  12.44364  12.34291  12.33709  12.26853 
       49        50        51        52        53        54        55        56 
 12.22757  12.23021  12.17159  12.18627  12.12249  12.09211  12.09981  12.09584 
       57        58        59        60        61        62        63        64 
 12.09701  12.05070  12.03800  12.01648  12.03630  12.04265  12.03306  12.03832 
       65        66        67        68        69        70        71        72 
 12.01891  12.02957  12.02650  12.03260  12.05505  12.05912  12.05548  12.06391 
       73        74        75        76        77        78        79        80 
 12.07102  12.07261  12.08883  12.08249  12.07888  12.08784  12.09927  12.12549 
       81        82        83        84        85        86        87        88 
 12.12826  12.13126  12.12796  12.14285  12.14607  12.15301  12.17057  12.17305 
       89        90        91        92        93        94        95        96 
 12.18268  12.17647  12.19278  12.20042  12.19723  12.21259  12.22006  12.22888 
       97        98        99       100 
 12.23484  12.23280  12.23929  12.25439 

	 Optimal number of boosting iterations: 60 
>   mstop(cvm)
[1] 60
>   plot(cvm)
> 
>   ### 25 bootstrap iterations (manually)
>   set.seed(290875)
>   bs25 <- rmultinom(25, n, rep(1, n)/n)
>   cvm <- cvrisk(model, folds = bs25)
>   print(cvm)

	 Cross-validated Squared Error (Regression) 
	 glmboost.formula(formula = DEXfat ~ ., data = bodyfat, control = boost_control(center = TRUE)) 

        1         2         3         4         5         6         7         8 
105.21681  90.39822  78.01859  67.62284  59.28276  51.69324  45.81663  40.72354 
        9        10        11        12        13        14        15        16 
 36.18268  32.82252  29.68052  27.34685  25.14741  23.32195  21.86297  20.62092 
       17        18        19        20        21        22        23        24 
 19.51134  18.57217  17.82785  17.19064  16.61903  16.14986  15.75519  15.42828 
       25        26        27        28        29        30        31        32 
 15.12715  14.86865  14.67645  14.47705  14.32909  14.19508  14.09503  14.02636 
       33        34        35        36        37        38        39        40 
 13.91859  13.85153  13.81214  13.73382  13.69756  13.66757  13.62300  13.58873 
       41        42        43        44        45        46        47        48 
 13.54895  13.53668  13.50329  13.49420  13.46374  13.45288  13.43445  13.44060 
       49        50        51        52        53        54        55        56 
 13.42223  13.41781  13.42916  13.41414  13.40484  13.40567  13.40934  13.40576 
       57        58        59        60        61        62        63        64 
 13.41607  13.41409  13.40710  13.40558  13.41583  13.41963  13.43354  13.42803 
       65        66        67        68        69        70        71        72 
 13.42735  13.42628  13.44171  13.45126  13.45371  13.45537  13.45598  13.46645 
       73        74        75        76        77        78        79        80 
 13.48861  13.47666  13.48980  13.50234  13.50078  13.51064  13.51178  13.53205 
       81        82        83        84        85        86        87        88 
 13.53838  13.53504  13.54260  13.54861  13.56030  13.56971  13.58088  13.58164 
       89        90        91        92        93        94        95        96 
 13.58812  13.59870  13.60281  13.61136  13.61502  13.61518  13.62406  13.62941 
       97        98        99       100 
 13.64013  13.64593  13.65394  13.65847 

	 Optimal number of boosting iterations: 53 
>   mstop(cvm)
[1] 53
> 
>   ### same
>   cvrisk(model)

	 Cross-validated Squared Error (Regression) 
	 glmboost.formula(formula = DEXfat ~ ., data = bodyfat, control = boost_control(center = TRUE)) 

        1         2         3         4         5         6         7         8 
113.34903  97.75110  84.39732  73.72527  64.95557  57.23990  50.70182  45.22719 
        9        10        11        12        13        14        15        16 
 40.82639  37.00885  33.50835  30.95360  28.55473  26.58338  24.94980  23.57663 
       17        18        19        20        21        22        23        24 
 22.35674  21.29944  20.50763  19.71728  19.03535  18.52925  18.07959  17.67749 
       25        26        27        28        29        30        31        32 
 17.30937  17.03299  16.79070  16.55563  16.37665  16.16714  16.02089  15.86690 
       33        34        35        36        37        38        39        40 
 15.73522  15.59649  15.49594  15.37960  15.30045  15.24378  15.14410  15.07273 
       41        42        43        44        45        46        47        48 
 15.00208  14.94143  14.92821  14.84110  14.81782  14.72153  14.73372  14.67178 
       49        50        51        52        53        54        55        56 
 14.65112  14.61564  14.57942  14.58378  14.53192  14.52370  14.51352  14.49515 
       57        58        59        60        61        62        63        64 
 14.46941  14.46838  14.44719  14.41961  14.41380  14.41644  14.41371  14.40680 
       65        66        67        68        69        70        71        72 
 14.38919  14.39623  14.38927  14.36407  14.38006  14.35352  14.36525  14.36855 
       73        74        75        76        77        78        79        80 
 14.34882  14.35304  14.35731  14.36211  14.34919  14.34586  14.35953  14.35271 
       81        82        83        84        85        86        87        88 
 14.34869  14.35215  14.35375  14.35588  14.35442  14.35995  14.36787  14.36094 
       89        90        91        92        93        94        95        96 
 14.35570  14.36483  14.36403  14.35646  14.37317  14.36747  14.37121  14.37671 
       97        98        99       100 
 14.37874  14.38462  14.37637  14.38360 

	 Optimal number of boosting iterations: 78 
> 
>   layout(matrix(1:2, ncol = 2))
>   plot(cvm)
> 
>   ### trees
>   blackbox <- blackboost(DEXfat ~ ., data = bodyfat)
Loading required package: party
Loading required package: grid
Loading required package: modeltools
Loading required package: stats4
Loading required package: coin
Loading required package: mvtnorm
Loading required package: zoo

Attaching package: 'zoo'


	The following object(s) are masked from package:base :

	 as.Date.numeric 

Loading required package: sandwich
Loading required package: strucchange
Loading required package: vcd
Loading required package: MASS
Loading required package: colorspace
>   cvtree <- cvrisk(blackbox)
>   plot(cvtree)
> 
> 
> 
> 
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx(); nameEx("gamboost")
> ### * gamboost
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: gamboost
> ### Title: Gradient Boosting with Smooth Components
> ### Aliases: gamboost
> ### Keywords: models nonlinear
> 
> ### ** Examples
> 
> 
>     ### a simple two-dimensional example: cars data
>     cars.gb <- gamboost(dist ~ speed, data = cars, dfbase = 4,
+                         control = boost_control(mstop = 50))
>     cars.gb

	 Model-based Boosting

Call:
gamboost(formula = dist ~ speed, data = cars, dfbase = 4, control = boost_control(mstop = 50))


	 Squared Error (Regression) 

Loss function: (y - f)^2 
 

Number of boosting iterations: mstop = 50 
Step size:  0.1 
Offset:  42.98 

Baselearner(s): 
[1] "baselearner(speed)"

>     AIC(cars.gb, method = "corrected")
[1] 6.669124
Optimal number of boosting iterations: 21 
Degrees of freedom (for mstop = 21): 6.393244 
> 
>     ### plot fit for mstop = 1, ..., 50
>     plot(dist ~ speed, data = cars)
>     tmp <- sapply(1:mstop(AIC(cars.gb)), function(i)
+         lines(cars$speed, predict(cars.gb[i]), col = "red"))
>     lines(cars$speed, predict(smooth.spline(cars$speed, cars$dist),
+                               cars$speed)$y, col = "green")
> 
>     ### artificial example: sinus transformation
>     x <- sort(runif(100)) * 10
>     y <- sin(x) + rnorm(length(x), sd = 0.25)
>     plot(x, y)
>     ### linear model
>     lines(x, fitted(lm(y ~ sin(x) - 1)), col = "red")
>     ### GAM
>     lines(x, fitted(gamboost(y ~ x,
+                     control = boost_control(mstop = 500))),
+           col = "green")
> 
> 
> 
> 
> cleanEx(); nameEx("glmboost")
> ### * glmboost
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: glmboost
> ### Title: Gradient Boosting with Component-wise Linear Models
> ### Aliases: glmboost glmboost.formula glmboost.matrix glmboost.default
> ###   plot.glmboost
> ### Keywords: models regression
> 
> ### ** Examples
> 
> 
>     ### a simple two-dimensional example: cars data
>     cars.gb <- glmboost(dist ~ speed, data = cars,
+                         control = boost_control(mstop = 5000))
>     cars.gb

	 Generalized Linear Models Fitted via Gradient Boosting

Call:
glmboost.formula(formula = dist ~ speed, data = cars, control = boost_control(mstop = 5000))


	 Squared Error (Regression) 

Loss function: (y - f)^2 
 

Number of boosting iterations: mstop = 5000 
Step size:  0.1 
Offset:  42.98 

Coefficients: 
(Intercept)       speed 
 -60.559044    3.932406 
attr(,"offset")
[1] 42.98

> 
>     ### coefficients should coincide
>     coef(cars.gb) + c(cars.gb$offset, 0)
(Intercept)       speed 
 -17.579044    3.932406 
attr(,"offset")
[1] 42.98
>     coef(lm(dist ~ speed, data = cars))
(Intercept)       speed 
 -17.579095    3.932409 
> 
>     ### plot fit
>     layout(matrix(1:2, ncol = 2))
>     plot(dist ~ speed, data = cars)
>     lines(cars$speed, predict(cars.gb), col = "red")
> 
>     ### alternative loss function: absolute loss
>     cars.gbl <- glmboost(dist ~ speed, data = cars,
+                          control = boost_control(mstop = 5000),
+                          family = Laplace())
>     cars.gbl

	 Generalized Linear Models Fitted via Gradient Boosting

Call:
glmboost.formula(formula = dist ~ speed, data = cars, control = boost_control(mstop = 5000),     family = Laplace())


	 Absolute Error 

Loss function: abs(y - f) 
 

Number of boosting iterations: mstop = 5000 
Step size:  0.1 
Offset:  36 

Coefficients: 
(Intercept)       speed 
 -29.532000    2.096213 
attr(,"offset")
[1] 36

> 
>     coef(cars.gbl) + c(cars.gbl$offset, 0)
(Intercept)       speed 
   6.468000    2.096213 
attr(,"offset")
[1] 36
>     lines(cars$speed, predict(cars.gbl), col = "green")
> 
>     ### Huber loss with adaptive choice of delta
>     cars.gbh <- glmboost(dist ~ speed, data = cars,
+                          control = boost_control(mstop = 5000),
+                          family = Huber())
> 
>     lines(cars$speed, predict(cars.gbh), col = "blue")
>     legend("topleft", col = c("red", "green", "blue"), lty = 1,
+            legend = c("Gaussian", "Laplace", "Huber"), bty = "n")
> 
>     ### plot coefficient path of glmboost
>     par(mai = par("mai") * c(1, 1, 1, 2.5))
>     plot(cars.gb)
> 
> 
> 
> 
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx(); nameEx("mboost")
> ### * mboost
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: mboost
> ### Title: Model-based Gradient Boosting
> ### Aliases: mboost mboost_fit
> ### Keywords: models nonlinear
> 
> ### ** Examples
> 
> 
>   data("bodyfat", package = "mboost")
> 
>   mod <- mboost(DEXfat ~ btree(age) + bols(waistcirc) + bbs(hipcirc), data = bodyfat)
Loading required package: party
Loading required package: grid
Loading required package: modeltools
Loading required package: stats4
Loading required package: coin
Loading required package: mvtnorm
Loading required package: zoo

Attaching package: 'zoo'


	The following object(s) are masked from package:base :

	 as.Date.numeric 

Loading required package: sandwich
Loading required package: strucchange
Loading required package: vcd
Loading required package: MASS
Loading required package: colorspace
> 
>   layout(matrix(1:3, nc = 3))
>   plot(mod, ask = FALSE)
> 
> 
> 
> 
> cleanEx(); nameEx("methods")
> ### * methods
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: methods
> ### Title: Methods for Gradient Boosting Objects
> ### Aliases: print.glmboost coef.glmboost coef.mboost print.mboost
> ###   AIC.mboost predict.mboost predict.glmboost mstop mstop.gbAIC
> ###   mstop.mboost mstop.cvrisk fitted.mboost logLik.mboost
> ###   hatvalues.mboost hatvalues.glmboost
> ### Keywords: methods
> 
> ### ** Examples
> 
> 
>     ### a simple two-dimensional example: cars data
>     cars.gb <- glmboost(dist ~ speed, data = cars,
+                         control = boost_control(mstop = 2000))
>     cars.gb

	 Generalized Linear Models Fitted via Gradient Boosting

Call:
glmboost.formula(formula = dist ~ speed, data = cars, control = boost_control(mstop = 2000))


	 Squared Error (Regression) 

Loss function: (y - f)^2 
 

Number of boosting iterations: mstop = 2000 
Step size:  0.1 
Offset:  42.98 

Coefficients: 
(Intercept)       speed 
 -60.331204    3.918359 
attr(,"offset")
[1] 42.98

> 
>     ### initial number of boosting iterations
>     mstop(cars.gb)
[1] 2000
> 
>     ### AIC criterion
>     aic <- AIC(cars.gb, method = "corrected")
>     aic
[1] 6.555391
Optimal number of boosting iterations: 1549 
Degrees of freedom (for mstop = 1549): 1.986856 
> 
>     ### coefficients for optimal number of boosting iterations
>     coef(cars.gb[mstop(aic)])
(Intercept)       speed 
 -59.751114    3.882873 
attr(,"offset")
[1] 42.98
>     plot(cars$dist, predict(cars.gb[mstop(aic)]),
+          ylim = range(cars$dist))
>     abline(a = 0, b = 1)
> 
> 
> 
> 
> cleanEx(); nameEx("survFit")
> ### * survFit
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: survFit
> ### Title: Survival Curves for a Cox Proportional Hazards Model
> ### Aliases: survFit survFit.mboost plot.survFit
> 
> 
> ### ** Examples
> 
> 
> library("survival")
> data("ovarian", package = "survival")
> 
> fm <- Surv(futime,fustat) ~ age + resid.ds + rx + ecog.ps
> fit <- glmboost(fm, data = ovarian, family = CoxPH(),
+     control=boost_control(mstop = 500))
> 
> S1 <- survFit(fit)
> S1
$surv
           [,1]
 [1,] 0.9658532
 [2,] 0.9301833
 [3,] 0.8925100
 [4,] 0.8535429
 [5,] 0.8119403
 [6,] 0.7708223
 [7,] 0.7297132
 [8,] 0.6826960
 [9,] 0.6325709
[10,] 0.5820681
[11,] 0.5218497
[12,] 0.4633558

$time
  1   2   3  22  23  24  25   5   7   8  10  11 
 59 115 156 268 329 353 365 431 464 475 563 638 

$n.event
 [1] 1 1 1 1 1 1 1 1 1 1 1 1

attr(,"class")
[1] "survFit"
> newdata <- ovarian[c(1,3,12),]
> S2 <- survFit(fit, newdata = newdata)
> S2
$surv
              1         3        12
 [1,] 0.9261555 0.9398046 0.9786631
 [2,] 0.8523142 0.8786884 0.9560666
 [3,] 0.7779547 0.8161129 0.9318412
 [4,] 0.7049307 0.7535397 0.9063720
 [5,] 0.6312922 0.6891727 0.8786885
 [6,] 0.5628548 0.6280552 0.8507935
 [7,] 0.4987027 0.5694634 0.8223344
 [8,] 0.4305029 0.5055683 0.7890285
 [9,] 0.3637907 0.4411647 0.7525473
[10,] 0.3027367 0.3802158 0.7146640
[11,] 0.2378723 0.3128096 0.6678203
[12,] 0.1829547 0.2529419 0.6203097

$time
  1   2   3  22  23  24  25   5   7   8  10  11 
 59 115 156 268 329 353 365 431 464 475 563 638 

$n.event
 [1] 1 1 1 1 1 1 1 1 1 1 1 1

attr(,"class")
[1] "survFit"
> 
> plot(S1)
> 
> 
> 
> cleanEx(); nameEx("wpbc")
> ### * wpbc
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: wpbc
> ### Title: Wisconsin Prognostic Breast Cancer Data
> ### Aliases: wpbc
> ### Keywords: datasets
> 
> ### ** Examples
> 
> 
>     data("wpbc", package = "mboost")
> 
>     ### fit logistic regression model with 100 boosting iterations
>     coef(glmboost(status ~ ., data = wpbc[,colnames(wpbc) != "time"], 
+                   family = Binomial()))
        (Intercept)         mean_radius        mean_texture      mean_perimeter 
       0.0000000000        0.0000000000       -0.0006008601        0.0000000000 
          mean_area     mean_smoothness    mean_compactness      mean_concavity 
       0.0000000000        0.0000000000        0.0000000000        0.0000000000 
 mean_concavepoints       mean_symmetry     mean_fractaldim           SE_radius 
       0.0000000000        0.0000000000        0.0000000000        0.0000000000 
         SE_texture        SE_perimeter             SE_area       SE_smoothness 
      -0.0885905098        0.0000000000        0.0006354682        0.0000000000 
     SE_compactness        SE_concavity    SE_concavepoints         SE_symmetry 
       0.0000000000       -1.7311449167       -3.7137850359        0.0000000000 
      SE_fractaldim        worst_radius       worst_texture     worst_perimeter 
       0.0000000000        0.0000000000        0.0000000000        0.0000000000 
         worst_area    worst_smoothness   worst_compactness     worst_concavity 
       0.0000968127        0.0000000000        0.0000000000        0.0000000000 
worst_concavepoints      worst_symmetry    worst_fractaldim               tsize 
       0.0000000000        0.0000000000        0.0000000000        0.0057306264 
             pnodes 
       0.0222476787 
attr(,"offset")
[1] -0.5835661
> 
> 
> 
> 
> ### * <FOOTER>
> ###
> cat("Time elapsed: ", proc.time() - get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  24.853 0.916 28.209 2.688 2.688 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
